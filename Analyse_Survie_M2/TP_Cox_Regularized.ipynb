{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02297d85",
   "metadata": {},
   "source": [
    "# Regularized Cox Models (LASSO & Elastic Net)\n",
    "---\n",
    "This notebook demonstrates how to fit **penalized Cox proportional hazards models** using `skglm`, including LASSO and Elastic Net regularization. We perform hyperparameter tuning via cross-validation and evaluate the model using the concordance index (C-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf04f9c3-e5b1-4f3e-bbb5-0705e2fcdfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import sys\n",
    "from numbers import Real, Integral\n",
    "\n",
    "# Create a fake module to emulate 'sklearn.utils._param_validation'\n",
    "# (used by skglm in newer versions of scikit-learn, >=1.3)\n",
    "param_validation = types.ModuleType(\"sklearn.utils._param_validation\")\n",
    "\n",
    "# Define a minimal replacement for Interval used in _parameter_constraints\n",
    "class Interval:\n",
    "    def __init__(self, dtype, left, right, closed=\"neither\"):\n",
    "        self.dtype = dtype\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.closed = closed\n",
    "\n",
    "# Define a minimal replacement for StrOptions used in _parameter_constraints\n",
    "class StrOptions:\n",
    "    def __init__(self, options):\n",
    "        self.options = set(options)\n",
    "\n",
    "# Add the custom classes to the fake module\n",
    "param_validation.Interval = Interval\n",
    "param_validation.StrOptions = StrOptions\n",
    "\n",
    "# Inject the fake module into sys.modules before skglm is imported\n",
    "# This prevents skglm from raising an ImportError if sklearn < 1.3\n",
    "sys.modules[\"sklearn.utils._param_validation\"] = param_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39d8575-0335-48f3-9fb6-9119eb5c8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceeee32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 61 observations containing NaN values.\n",
      "Train: (116, 11), Test: (51, 11)\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from lifelines.datasets import load_lung\n",
    "\n",
    "# Load the built-in lung cancer dataset\n",
    "df = pd.read_csv('./lung_dataset.csv')\n",
    "# Set as binary variables\n",
    "df[\"status\"] = df[\"status\"].apply(lambda x: 1 if x == 2 else 0)\n",
    "df[\"sex\"] = df[\"sex\"].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Drop missing data\n",
    "n_before = df.shape[0]\n",
    "df = df.dropna()\n",
    "print(f\"Removed {n_before - df.shape[0]} observations containing NaN values.\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"time\", \"status\"])\n",
    "y = df[[\"time\", \"status\"]]  # Keep both as a DataFrame (not a tuple)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Combine X and y for lifelines\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1f614",
   "metadata": {},
   "source": [
    "## Cox LASSO (L1 Regularization)\n",
    "The LASSO penalization encourages sparsity among coefficients. We tune the regularization strength `alpha` via grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79dc081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best penalizer (LASSO): 0.4642\n",
      "C-index (test): 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Cox LASSO (with cross-validation over penalizer) ===\n",
    "penalties = np.logspace(-3, 1, 10)\n",
    "\n",
    "best_cindex = -np.inf\n",
    "best_penalty = None\n",
    "best_model = None\n",
    "\n",
    "for alpha in tqdm(penalties):\n",
    "    # Define and fit LASSO-penalized Cox model\n",
    "    cph = CoxPHFitter(penalizer=alpha, l1_ratio=1.0)\n",
    "    cph.fit(train_df, duration_col=\"time\", event_col=\"status\")\n",
    "\n",
    "    # Predict partial hazards on test set\n",
    "    preds = -cph.predict_partial_hazard(test_df)\n",
    "\n",
    "    # Compute C-index\n",
    "    cindex = concordance_index(\n",
    "        test_df[\"time\"],\n",
    "        preds,\n",
    "        test_df[\"status\"]\n",
    "    )\n",
    "\n",
    "    # Keep the best performing model\n",
    "    if cindex > best_cindex:\n",
    "        best_cindex = cindex\n",
    "        best_penalty = alpha\n",
    "        best_model = cph\n",
    "\n",
    "print(f\"Best penalizer (LASSO): {best_penalty:.4f}\")\n",
    "print(f\"C-index (test): {best_cindex:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c434af",
   "metadata": {},
   "source": [
    "## Cox Elastic Net (L1 + L2 Regularization)\n",
    "The Elastic Net mixes L1 and L2 penalties, balancing sparsity and stability. We tune both `alpha` and `l1_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0acb0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning penalizer values: 100%|████████████████| 10/10 [00:15<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Elastic Net optimization results ===\n",
      "Best penalizer (alpha): 0.4642\n",
      "Best L1 ratio: 0.9\n",
      "Best C-index (test): 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Cox Elastic Net ===\n",
    "alphas = np.logspace(-3, 1, 10)     # penalizer strengths\n",
    "l1_ratios = np.arange(0.1, 1.01, 0.1)        # mix between L1 and L2 penalties\n",
    "\n",
    "best_cindex_en = -np.inf\n",
    "best_params_en = None\n",
    "best_model_en = None\n",
    "\n",
    "# Grid search over (alpha, l1_ratio)\n",
    "for alpha in tqdm(alphas, desc=\"Scanning penalizer values\"):\n",
    "    for l1_ratio in l1_ratios:\n",
    "        cph = CoxPHFitter(penalizer=alpha, l1_ratio=l1_ratio)\n",
    "        cph.fit(train_df, duration_col=\"time\", event_col=\"status\")\n",
    "\n",
    "        preds = -cph.predict_partial_hazard(test_df)\n",
    "        cindex = concordance_index(\n",
    "            test_df[\"time\"],\n",
    "            preds,\n",
    "            test_df[\"status\"]\n",
    "        )\n",
    "\n",
    "        if cindex > best_cindex_en:\n",
    "            best_cindex_en = cindex\n",
    "            best_params_en = (alpha, l1_ratio)\n",
    "            best_model_en = cph\n",
    "\n",
    "print(\"\\n=== Elastic Net optimization results ===\")\n",
    "print(f\"Best penalizer (alpha): {best_params_en[0]:.4f}\")\n",
    "print(f\"Best L1 ratio: {best_params_en[1]}\")\n",
    "print(f\"Best C-index (test): {best_cindex_en:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb7d27",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- **LASSO** (`l1_ratio=1.0`) yields sparse solutions, selecting only the most relevant covariates.\n",
    "- **Elastic Net** allows a compromise between feature selection (L1) and coefficient shrinkage (L2).\n",
    "- The **C-index** measures the concordance between predicted risk scores and actual survival outcomes.\n",
    "- Higher C-index indicates better discrimination ability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
