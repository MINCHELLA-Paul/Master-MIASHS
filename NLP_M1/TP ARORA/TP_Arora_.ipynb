{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71302221",
   "metadata": {},
   "source": [
    "# TP: Applying Arora's Method for Sentence Embeddings\n",
    "\n",
    "* Master 1 – MIASHS, Université Lyon 2  \n",
    "* December 2025  \n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "**Global goal:** Build a model that takes an SMS message as input and predicts whether it is **spam** or **not spam**.  \n",
    "To achieve this, you will compute sentence embeddings using the method proposed by Arora *et al.* (2017):  \n",
    "https://openreview.net/forum?id=SyK00v5xx\n",
    "\n",
    "**Steps of the practical session:**\n",
    "\n",
    "1. Download the **SMS Spam Collection Dataset**:  \n",
    "   https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset\n",
    "\n",
    "2. Extract **word embeddings** for each observation using **Gensim Word2Vec**, forming a dictionary `{token: embedding}`.\n",
    "\n",
    "3. Compute the **sentence embedding** $v_s^i$ for each observation using the **Arora SIF method**.\n",
    "\n",
    "4. Train a **RandomForestClassifier**, a **Logistic Regression**, a **Neural Network** or any model you want using sentence embeddings as features.\n",
    "\n",
    "5. Evaluate your Classifier (Precision, Recall, Accuracy, F1-score, etc.).\n",
    "\n",
    "\n",
    "### Targeted Model\n",
    "\n",
    "* $N$: dimension of the embedding space.  \n",
    "* $J$: number of tokens/words in the sentence.  \n",
    "* $v_s$: sentence embedding computed using the Arora method from word embeddings $(w_1, \\dots, w_J)$.  \n",
    "* $\\delta$: binary target (1 for spam, 0 for non-spam).\n",
    "\n",
    "The global learning pipeline is:\n",
    "\n",
    "$$\n",
    "\\text{phrase} \\ \\xrightarrow[\\mathrm{word. embd}]{\\mathrm{extract.} } \\quad \\left(w_1, \\dots, w_J \\right) \\in \\mathbb{R}^{N \\times J} \\quad \\xrightarrow[]{\\mathrm{Arora} }  \\quad v_s  \\in \\mathbb{R}^{N} \\quad \\xrightarrow[]{\\boxed{ \\mathrm{model} }} \\quad \\delta^{\\text{pred}} \\in \\{0,1\\}\n",
    "$$\n",
    "\n",
    "\n",
    "### Python Methods for Arora et al. (2017)\n",
    "\n",
    "The official GitHub repository of the method is available here:  \n",
    "https://github.com/PrincetonML/SIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b7787-f402-4586-ad76-5d855ff945f6",
   "metadata": {},
   "source": [
    "## I) Import Required Packages and Data\n",
    "### I)1) Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce0bb5a-f2b7-45fa-a3c2-aee6e7f836d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp_arora_pkg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0589c060-37ed-498f-bd16-e645e626a3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully with encoding='ISO-8859-1'.\n"
     ]
    }
   ],
   "source": [
    "df = load_text_classification_dataset('./spam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468601a2-d321-4cf1-b20d-68d2a5cb4158",
   "metadata": {},
   "source": [
    "#### Display the first few rows of the DataFrame to inspect its structure and verify that it was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0cf74-d71c-4ac1-a74a-31c4b9d008e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a38896-433b-46ce-85c1-5ba1b276e66c",
   "metadata": {},
   "source": [
    "### I)2) Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cbd3a4-f2fb-4b83-bd1f-e179b0742f8e",
   "metadata": {},
   "source": [
    "#### Use the descriptive statistics and visualization functions provided in the tp_arora_pkg package to explore the dataset by computing summary statistics and plotting the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb02f0-b00d-430a-9ca4-b66dd08e0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92481bc-1609-44ef-a823-766fdb22a306",
   "metadata": {},
   "source": [
    "## II) NLP Model encoding\n",
    "\n",
    "#### Additional Resources\n",
    "\n",
    "Here are a few useful references to help you explore Word2Vec and word embeddings more deeply:\n",
    "\n",
    "* https://radimrehurek.com/gensim/models/word2vec.html  \n",
    "  *Official Gensim documentation for the Word2Vec model.*\n",
    "\n",
    "* https://datascientest.com/nlp-word-embedding-word2vec  \n",
    "  *A clear introduction to Word2Vec and its role in NLP.*\n",
    "\n",
    "Feel free to explore further resources (blog posts, tutorials, videos, research papers) to better understand how word embeddings, sentence embeddings, and the Arora SIF method fit into modern NLP workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da4667-a275-4fc0-b31d-cf17e2fc9141",
   "metadata": {},
   "source": [
    "### II)1) Word embeddings extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958942ad-7c8b-4e3a-872e-117eba465180",
   "metadata": {},
   "source": [
    "#### Use the word-embedding extraction function from the package to transform each text entry into its corresponding set of word embeddings.  \n",
    "Have a look at the first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5198ee6b-c16f-4673-b8f9-cfcd67ab4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145f5b1-48fd-4215-a24f-4c8a2a0b587e",
   "metadata": {},
   "source": [
    "### II)2) Sentence embeddings computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae119b0-7d80-4d52-af73-c2b55343ee24",
   "metadata": {},
   "source": [
    "#### Apply the Arora sentence-embedding method to the word-embedding dictionary of each document, then display the first few resulting sentence embeddings to verify that the transformation worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e86dd-e97e-4d15-9229-d684202e013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb0502-a5d4-4065-82e9-f2af7f112d2d",
   "metadata": {},
   "source": [
    "## III) Training a Classification Model\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Using the sentence embeddings computed with Arora's method, build a model that predicts whether a message should be classified as **SPAM** or **not SPAM**.\n",
    "\n",
    "   * First, **split** the dataset into a training set and a test set.  \n",
    "     (What is the explanatory variable? What is the target variable?)\n",
    "\n",
    "   * Import a classification model (RandomForest, Logistic Regression, Neural Network, or any other classifier).  \n",
    "     Instantiate it and train it on the **training** portion of the dataset.\n",
    "\n",
    "   * Evaluate the **quality** of your model by comparing predictions on the **test set** with the true labels.  \n",
    "     (*Which metrics can be used for this?* Think about Accuracy, Precision, Recall, F1-score, etc. but also Brier Score or other calibration metrics.)\n",
    "  \n",
    "\n",
    "    * Display the **confusion matrix**.\n",
    "  \n",
    "\n",
    "For a complete piece of work, you should put **several models in competition** (to be as exhaustive as possible) and compare both their discrimination and calibration results in order to reach a reasonably rigorous conclusion. \n",
    "\n",
    "2. Suppose you have obtained a trained model `classif_spam` whose performance is satisfactory.  \n",
    "   What happens when you apply it to an **external dataset**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bde060-78e7-44c8-902f-0057c7f33d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, brier_score_loss\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### EXAMPLES : you can take any classifier you want\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79103a-eb84-46a5-a733-ba0bb62b2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0ee5712-8d33-4927-acac-dffb665fb617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing word embeddings...: 100%|████████████| 4/4 [00:00<00:00, 34807.50it/s]\n",
      "Computing sentence embeddings...: 100%|█████████| 4/4 [00:00<00:00, 4666.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predictions on New Messages ---\n",
      "MLPClassifier predictions : [0 0 0 0]\n",
      "RandomForest predictions  : [0 0 0 0]\n",
      "Logistic Regression (LASSO) predictions : [0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Artificial dataset of new SMS\n",
    "data = {\n",
    "    'text': [\n",
    "        'what about',\n",
    "        'see the last new of our model',\n",
    "        'win last phone',\n",
    "        'WINNER!! As a valued network customer you have been selected to receive a price'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_newdata = pd.DataFrame(data)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Extract embeddings and compute Arora sentence embeddings\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "df_newdata = extract_word_embeddings(df_newdata)\n",
    "df_newdata = arora_methods(df_newdata, remove_pc_nbr=0)\n",
    "\n",
    "# Convert embeddings to numpy format\n",
    "X_new = np.stack(df_newdata['sentence_embeddings'].values)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Predictions for each model\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Predictions on New Messages ---\")\n",
    "\n",
    "# 1. Neural Network (MLPClassifier)\n",
    "y_pred_mlp = clf_nn.predict(X_new)\n",
    "print(\"MLPClassifier predictions :\", y_pred_mlp)\n",
    "\n",
    "# 2. Random Forest\n",
    "y_pred_rf = clf_rf.predict(X_new)\n",
    "print(\"RandomForest predictions  :\", y_pred_rf)\n",
    "\n",
    "# 3. Logistic Regression with LASSO\n",
    "y_pred_lr = clf_lr.predict(X_new)\n",
    "print(\"Logistic Regression (LASSO) predictions :\", y_pred_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
